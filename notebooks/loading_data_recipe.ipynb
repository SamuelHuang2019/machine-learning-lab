{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Loading data in PyTorch\n",
    "=======================\n",
    "PyTorch features extensive neural network building blocks with a simple,\n",
    "intuitive, and stable API. PyTorch includes packages to prepare and load\n",
    "common datasets for your model.\n",
    "\n",
    "Introduction\n",
    "------------\n",
    "At the heart of PyTorch data loading utility is the\n",
    "`torch.utils.data.DataLoader <https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader>`__\n",
    "class. It represents a Python iterable over a dataset. Libraries in\n",
    "PyTorch offer built-in high-quality datasets for you to use in\n",
    "`torch.utils.data.Dataset <https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset>`__.\n",
    "These datasets are currently available in:\n",
    "\n",
    "* `torchvision <https://pytorch.org/docs/stable/torchvision/datasets.html>`__\n",
    "* `torchaudio <https://pytorch.org/audio/datasets.html>`__\n",
    "* `torchtext <https://pytorch.org/text/datasets.html>`__\n",
    "\n",
    "with more to come.\n",
    "Using the Yesno dataset from ``torchaudio.datasets.YESNO``, we will\n",
    "demonstrate how to effectively and efficiently load data from a PyTorch\n",
    "``Dataset`` into a PyTorch ``DataLoader``.\n",
    "\n",
    "Setup\n",
    "-----\n",
    "Before we begin, we need to install ``torchaudio`` to have access to the\n",
    "dataset.\n",
    "\n",
    "::\n",
    "\n",
    "   pip install torchaudio\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps\n",
    "-----\n",
    "\n",
    "1. Import all necessary libraries for loading our data\n",
    "2. Access the data in the dataset\n",
    "3. Loading the data\n",
    "4. Iterate over the data\n",
    "5. [Optional] Visualize the data\n",
    "\n",
    "\n",
    "1. Import necessary libraries for loading our data\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "For this recipe, we will use ``torch`` and ``torchaudio``. Depending on\n",
    "what built-in datasets you use, you can also install and import\n",
    "``torchvision`` or ``torchtext``.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Access the data in the dataset\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "The Yesno dataset in ``torchaudio`` features sixty recordings of one\n",
    "individual saying yes or no in Hebrew; with each recording being eight\n",
    "words long (`read more here <https://www.openslr.org/1/>`__).\n",
    "\n",
    "``torchaudio.datasets.YESNO`` creates a dataset for YesNo.\n",
    "\n",
    "::\n",
    "\n",
    "   torchaudio.datasets.YESNO(\n",
    "     root,\n",
    "     url='http://www.openslr.org/resources/1/waves_yesno.tar.gz',\n",
    "     folder_in_archive='waves_yesno',\n",
    "     download=False,\n",
    "     transform=None,\n",
    "     target_transform=None)\n",
    "\n",
    "Each item in the dataset is a tuple of the form: (waveform, sample_rate,\n",
    "labels).\n",
    "\n",
    "You must set a ``root`` for the Yesno dataset, which is where the\n",
    "training and testing dataset will exist. The other parameters are\n",
    "optional, with their default values shown. Here is some additional\n",
    "useful info on the other parameters:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0.00/4.49M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c76db55e29d04101b0086e919a9fd993"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# * ``download``: If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again.\n",
    "# * ``transform``: Using transforms on your data allows you to take it from its source state and transform it into data that’s joined together, de-normalized, and ready for training. Each library in PyTorch supports a growing list of transformations.\n",
    "# * ``target_transform``: A function/transform that takes in the target and transforms it.\n",
    "# \n",
    "# Let’s access our Yesno data:\n",
    "# \n",
    "\n",
    "# A data point in Yesno is a tuple (waveform, sample_rate, labels) where labels \n",
    "# is a list of integers with 1 for yes and 0 for no.\n",
    "yesno_data_trainset = torchaudio.datasets.YESNO('../data', download=True)\n",
    "\n",
    "# Pick data point number 3 to see an example of the the yesno_data:\n",
    "n = 3\n",
    "waveform, sample_rate, labels = yesno_data[n]\n",
    "print(\"Waveform: {}\\nSample rate: {}\\nLabels: {}\".format(waveform, sample_rate, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using this data in practice, it is best practice to provision the\ndata into a “training” dataset and a “testing” dataset. This ensures\nthat you have out-of-sample data to test the performance of your model.\n\n3. Loading the data\n~~~~~~~~~~~~~~~~~~~~~~~\n\nNow that we have access to the dataset, we must pass it through\n``torch.utils.data.DataLoader``. The ``DataLoader`` combines the dataset\nand a sampler, returning an iterable over the dataset.\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(yesno_data,\n                                          batch_size=1,\n                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Iterate over the data\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nOur data is now iterable using the ``data_loader``. This will be\nnecessary when we begin training our model! You will notice that now\neach data entry in the ``data_loader`` object is converted to a tensor\ncontaining tensors representing our waveform, sample rate, and labels.\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for data in data_loader:\n  print(\"Data: \", data)\n  print(\"Waveform: {}\\nSample rate: {}\\nLabels: {}\".format(data[0], data[1], data[2]))\n  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. [Optional] Visualize the data\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\nYou can optionally visualize your data to further understand the output\nfrom your ``DataLoader``.\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n\nprint(data[0][0].numpy())\n\nplt.figure()\nplt.plot(waveform.t().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have successfully loaded data in PyTorch.\n\nLearn More\n----------\n\nTake a look at these other recipes to continue your learning:\n\n- `Defining a Neural Network <https://pytorch.org/tutorials/recipes/recipes/defining_a_neural_network.html>`__\n- `What is a state_dict in PyTorch <https://pytorch.org/tutorials/recipes/recipes/what_is_state_dict.html>`__\n\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-7004eb84",
   "language": "python",
   "display_name": "PyCharm (machine-learning-lab)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}